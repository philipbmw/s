{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 6 학습 관련 기술들"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ■ 학습 내용 \n",
    "#### <u><b>신경망 학습의 핵심 개념들에 대한 분석</b><br></u>\n",
    "* <b> 6.1 매개변수 갱신 방법 </b>\n",
    "<font color=\"blue\"><font size=\"1\"><i>가중치 매개변수의 최적값을 탐색하는 최적화 방법</i></font></font>\n",
    " - 확률적 경사 하강법(SSD)\n",
    " - 모멘텀\n",
    " - AdaGrad\n",
    " - Adam\n",
    "* <b> 6.2 가중치의 초깃값 </b>\n",
    "<font color=\"blue\"><font size=\"1\"><i>가중치 초깃값을 정하는 방법은 <u>올바른 학습을 하는데 매우 중요함</u></i></font></font>\n",
    " - Xavier\n",
    " - He\n",
    "* <b> 6.3 배치 정규화 </b>\n",
    "<font color=\"blue\"><font size=\"1\"><i>배치 정규화를 이용하면 <u>학습을 빠르게 진행할 수 있으며, 초깃값에 영향을 덜 받게 됨</u></i></font></font>\n",
    "* <b> 6.4 바른 학습을 위해 </b>\n",
    " - 오버피팅\n",
    " - 가중치 감소 \n",
    "  <font color=\"blue\"><font size=\"1\"><i>오버피팅의 대응책인 정규화 방법</i></font></font>\n",
    " - 드롭아웃 \n",
    " <font color=\"blue\"><font size=\"1\"><i>오버피팅의 대응책인 정규화 방법</i></font></font>\n",
    "* <b> 6.5 적절한 하이퍼파라미터 값 찾기 </b>\n",
    "#### <font color=\"red\"><b> => 신경망 (딥러닝) 학습의 효율과 정확도를 높일 수 있음</b></font><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 매개변수 갱신 <font color=\"blue\"><font size=\"2\"><i>가중치 매개변수의 최적값을 탐색하는 최적화 방법</i></font></font>\n",
    " - 확률적 경사 하강법(SSD)\n",
    " - 모멘텀\n",
    " - AdaGrad\n",
    " - Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 신경망 학습의 목적 \n",
    " - 손실 함수의 값을 가능한 한 낮추는 매개변수를 찾는 것\n",
    " - 최적 매개변수를 찾는 문제\n",
    " - <b> 최적화<sup>optimization</sup></b>\n",
    " \n",
    " <br>\n",
    "\n",
    "* 지금까지 최적의 매개변수 값을 찾는 단서\n",
    " - 매개변수의 기울기 (미분)를 이용\n",
    " - 매개변수의 기울기를 구해, 기울어진 방향으로 매개변수 값을 갱신하는 일을 몇 번이고 반복해서 점점 최적의 매개변수를 찾음\n",
    " - <b> 확률적 경사 하강법(SGD) </b>\n",
    " \n",
    " <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.2 확률적 경사 하강법(SGD) \n",
    "<img src=\"1.jpg\">\n",
    "* w : 갱신할 가중치 매개변수\n",
    "* ∂L/∂W : W에 대한 손실 함수의 기울기\n",
    "* n : 학습률\n",
    " - 실제로는 0.01이나 0.001과 같은 값을 미리 정해서 사용\n",
    "* ← : 우변의 값으로 좌변의 값을 갱신함\n",
    "* <b><font size=\"3\"><font color=\"Red\"> => SGD는 기울어진 방향으로 일정 거리만 가겠다는 단순한 방법 </font></font></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    def __init__(self, lr=0.01):\n",
    "        self.lr = lr;\n",
    "    \n",
    "    def update(self, params, grads):\n",
    "        for key in params.keys():\n",
    "            params[key] -= self.lr * grads[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* lr : learning rate (학습률)\n",
    " - 인스턴스 변수로 유지\n",
    "* update(params, grads) 메서드\n",
    " - SGD 과정에서 반복해서 불리게 됨\n",
    " - params, grads : 딕셔너리 변수\n",
    " - params['W1'], grads[W1'] 과 같이 각각 가중치 매개변수와 기울기 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TwoLayerNet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-a2e448e06712>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnetwork\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTwoLayerNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[1;33m...\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TwoLayerNet' is not defined"
     ]
    }
   ],
   "source": [
    "network = TwoLayerNet(...)\n",
    "optimizer = SGD()\n",
    "\n",
    "for i in range(10000):\n",
    "    ...\n",
    "    x_batch, t_batch = get_mini_batch(...) #미니배치\n",
    "    grads = network.gradient(x_batch, t_batch)\n",
    "    params = network.params\n",
    "    optimizer.update(params, grads)\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* optimizer : '최적화를 행하는 자' 라는 뜻의 단어\n",
    " - 이 코드에서는 SGD()가 그 역할을 함\n",
    " - 매개변수 갱신은 optimizer가 책임지고 수행하기 때문에 \n",
    " - <b>optimizer에 매개변수와 기울기 정보만 넘겨주면 됨</b>\n",
    " \n",
    " <br>\n",
    " \n",
    "* (이처럼) <b>최적화를 담당하는 클래스를 분리해 구현하면 기능을 모듈화하기 좋음</b>\n",
    " - ex) 모멘텀이라는 최적화 기법 역시 update(params, grads)라는 공통의 메서드를 갖도록 구현\n",
    " - 그때, optimizer = SGD() 문장을 optimizer = Momentum() 으로만 변경하면 모멘텀으로 바꿀 수 있게 됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.3 SGD의 단점\n",
    "* SGD는 단순하고 구현이 쉽지만, 문제에 따라서 비효율적일 때가 있음\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src=\"2.jpg\">\n",
    "\n",
    "* 이 함수는 '밥그릇'을 x축 방향으로 늘인 듯한 모습 (왼쪽)이고, 실제로 그 등고선은 오른쪽과 같이 x축 방향으로 늘린 타원 (오른쪽)으로 되어 있음\n",
    "\n",
    "<img src=\"3.jpg\">\n",
    "\n",
    "* [식 6.2] 함수의 기울기를 그려보면,\n",
    " - 기울기는 y축 방향은 크고 x축 방향은 작다는 것이 특징\n",
    " - y축 방향은 가파른데 x축 방향은 완만한 것\n",
    " \n",
    "* 여기에서 주의할 점은,\n",
    " - [식 6.2]가 최솟값이 되는 장소는 (x,y) = (0,0)이지만\n",
    " - [그림 6-2]가 보여주는 기울기 대부분은 (0,0) 방향을 가리키지 않는다는 것\n",
    "\n",
    "<img src=\"4.jpg\">\n",
    "\n",
    "* [그림 6-1] 함수에 SGD 적용\n",
    " - 탐색 시작하는 장소(초깃값)는 (x,y) = (-7.0, 2.0)으로 시작\n",
    " - SGD는 심하게 굽이진 움직임을 보임\n",
    " - 상당히 비효율적인 움직임\n",
    " - <b> SGD의 단점은 비등방성 함수 (방향에 따라 성질, 즉 여기에서는 기울기가 달라지는 함수)에서는 탐색 경로가 비효율적이라는 것 </b>\n",
    " \n",
    "<img src=\"5.jpg\">\n",
    "\n",
    "* (다음으로) SGD의 이러한 단점을 개선 및 SGD를 대체하는 세 가지 기법을 소개\n",
    " - 모멘텀\n",
    " - AdaGrad\n",
    " - Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.4 모멘텀\n",
    "\n",
    "* <b>모멘텀</b><sup>Momentum</sup>\n",
    " - '운동량' 뜻하는 단어\n",
    " - 물리 속성과 관련이 있음\n",
    "\n",
    "<img src=\"6.jpg\">\n",
    "\n",
    "(SGD와 유사)\n",
    "* W : 갱신할 가중치 매개변수\n",
    "* ∂L/∂W : W에 대한 손실 함수의 기울기\n",
    "* n : 학습률\n",
    "* <b>v</b> <font color=\"red\"><b>(새로운 변수)</b></font> : 물리에서 말하는 속도<sup>velocity</sup>\n",
    "\n",
    "<br>\n",
    "\n",
    "* [식 6.3]\n",
    " - 기울기 방향으로 힘을 받아 물체가 가속된다는 물리 법칙을 나타냄\n",
    " - ∝v : 물체가 아무런 힘을 받지 않을 때 서서히 하강시키는 역할 (∝: 0.9 등의 값으로 설정), \n",
    "   - 물리에서는 지면 마찰이나 공기 저항에 해당\n",
    "* [그림 6-4]\n",
    " - 모멘텀은 공이 그릇의 바닥을 구르는 듯한 움직임을 보임\n",
    "\n",
    " \n",
    "<img src=\"7.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Momentum:\n",
    "    def __init__(self, lr=0.01, momentum=0.9):\n",
    "        self.lr = lr\n",
    "        self.momentum = momentum\n",
    "        self.v = None\n",
    "        \n",
    "        def update(self, params, grads):\n",
    "            if self.v is None:\n",
    "                self.v = {}\n",
    "                for key, val in params.items():\n",
    "                    self.v[key] = np.zeros_like(val)\n",
    "                    \n",
    "                    for key in params.keys():\n",
    "                        self.v[key] = self.momentum*self.v[key] - self.lr*grads[key]\n",
    "                        params[key] += self.v[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* v\n",
    " - 인스턴스 변수\n",
    " - 물체의 속도\n",
    " - 초기화 때는 아무 값도 담지 않고, \n",
    " - update()가 처음 호출될 때 매개변수와 같은 구조의 데이터를 딕셔너리 변수로 저장\n",
    "* 나머지 부분은 [식 6.3]과 [식 6.4]를 간단히 코드로 옮긴 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [그림 6-5] <b>모멘텀의 갱신 경로</b>는 공이 그릇 바닥을 구르듯 움직임\n",
    "* SGD와 비교하면 '지그재그 정도'가 덜함\n",
    " - x축의 힘은 아주 작지만 방향은 변하지 않아서 한 방향으로 일정하게 가속하기 때문\n",
    " - y축의 힘은 크지만 위아래로 번갈아 받아서 상충하여 y축 방향의 속도는 안정적이지 않음\n",
    " - 전체적으로는 SGD보다 x축 방향으로 빠르게 다가갈 수 있어서 지그재그 움직임을 줄일 수 있음\n",
    "\n",
    "<img src=\"8.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.5 AdaGrad\n",
    "\n",
    "* 신경망 학습에서는 학습률(n) 값이 중요\n",
    " - 이 값이 너무 작으면 학습 시간이 너무 길어지고,\n",
    " - 반대로 너무 크면 발산하여 올바른 학습을 할 수 없음\n",
    "* <b>학습률 감소</b><sup>learning rate decay</sup> - 학습률 정하는 효과적인 기술\n",
    " - 학습을 진행하면서 학습률을 점자 줄여가는 방법\n",
    " - 처음에는 크게 학습하다가 조금씩 작게 학습한다는 얘기 (실제 신경망 학습에 자주 쓰임)\n",
    " \n",
    "<br>\n",
    "\n",
    "* <b>AdaGrad</b>\n",
    " - 학습률을 서서히 낮추는 가장 간단한 방법은, 매개변수 '전체'의 학습률 값을 일괄적으로 낮추는 것\n",
    " - 이를 더욱 발전시킨 것 -> Adagrad\n",
    " - '각각의' 매개변수에 '맞춤형' 값을 만들어 준다는 개념\n",
    " - 개별 매개변수에 적응적으로<sup>adaptive</sup> 학습률을 조정하면서 학습을 진행\n",
    " \n",
    "<br>\n",
    "\n",
    "<img src=\"9.jpg\">\n",
    "\n",
    "\n",
    "* AdaGrad의 갱신 방법 (수식적으로 표현)\n",
    " - W : 갱신할 가중치 매개변수\n",
    " - ∂L/∂W : W에 대한 손실 함수의 기울기\n",
    " - n : 학습률\n",
    " - <b>h</b> <font color=\"red\"><b>(새로운 변수)</b></font>\n",
    "   - [식 6.5]에서 보듯 기존 기울기 값을 제곱하여 계속 더해줌 (⊙ 기호는 행렬의 원소별 곱셈을 의미)\n",
    "   - 매개변수를 갱신할 때 1/루트h 을 곱해 학습률을 조정\n",
    "   - 매개변수의 원소 중에서 많이 움직인 (크게 갱신된) 원소는 학습률이 낮아진다는 뜻\n",
    "     - <b>학습률 감소가 매개변수의 원소마다 다르게 적용됨을 뜻함</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AdaGrad:\n",
    "    def __init__(self, lr=0.01):\n",
    "        self.lr = lr\n",
    "        self.h = None\n",
    "        \n",
    "        def update(self, params, grads):\n",
    "            if self.h is None:\n",
    "                self.h = {}\n",
    "                for key, val in params.items():\n",
    "                    self.h[key] = np.zeros_like(val)\n",
    "                    \n",
    "                    for key in params.keys():\n",
    "                        self.h[key] += grads[key] * grads[key]\n",
    "                        params[key] -= self.lr * grads[key] / (np.sqrt(self.h[key]) + 1e-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 모멘텀 구현 코드와 거의 유사\n",
    "* 코드상 바뀐 부분\n",
    " - v -> h로 바뀜\n",
    " - 마지막 for문에서의 마지막 두줄\n",
    "   - <font color=\"red\">※ 주의할 점은 <b>1e-7</b> 이라는 작은 값을 더하는 부분 </font>\n",
    "   - 이 작은 값은 self.h[key]에 0이 담겨 있다 해도 0으로 나누는 사태를 막아줌"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [그림 6-6]을 보면, 최솟값을 향해 효율적으로 움직이는 것을 알 수 있음\n",
    " - y축 방향은 기울기가 커서 처음에는 크게 움직이지만, 그 큰 움직임에 비례해 갱신 정도도 큰 폭으로 작아지도록 조정됨\n",
    " - 따라서, y축 방향으로 갱신 강도가 약해졌고, 지그재그 움직임이 줄어듦\n",
    "<img src=\"10.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.6 Adam\n",
    "\n",
    "* (Review)\n",
    " - 모멘텀 : 공이 그릇을 구르는 듯한 물리 법칙에 따르는 움직임을 보임\n",
    " - AdaGrad : 매개변수의 원소마다 적응적으로 갱신 정도를 조정\n",
    " \n",
    "<br>\n",
    "\n",
    "* <font size\"3\"><b>Adam</b></font> ('이 두 기법을 융합하면 어떨까'라는 생각을 기초로 만든 기법)\n",
    " - 2015년에 제안된 새로운 방법\n",
    " - 이론은 다소 복잡하지만, 직관적으로는 모멘텀과 AdaGrad를 융합한 듯한 방법\n",
    "* Adam의 특징\n",
    " - 두 방법의 이점을 조합했기 때문에 매개변수 공간을 효율적으로 탐색 가능\n",
    " - 하이퍼파라미터의 '편향 보정'이 진행됨\n",
    "\n",
    "<br>\n",
    "\n",
    "* [그림 6-7]과 같이 Adam 갱신 과정도 그릇에서 공이 구르듯 움직임\n",
    " - 모멘텀과 비슷한 패턴이지만, 모멘텀 때보다 공의 좌우 흔들림이 적음\n",
    "  - <b>학습의 갱신 강도를 적응적으로 조정해서 얻는 혜택</b>\n",
    "<img src=\"11.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.7 어느 갱신 방법을 이용할 것인가?\n",
    "\n",
    "* SGD, 모멘텀, AdaGrad, Adam 네 기법의 결과 비교 분석\n",
    " - 사용한 기법에 따라 갱신 경로가 다름\n",
    " - 그림으로만 보면, AdaGrad가 가장 나은 것 같은데 ...\n",
    "   1. <font color=\"blue\"><b>결과는 풀어야 할 문제가 무엇이냐에 따라 달라지므로 주의해야 함</b></font>\n",
    "   2. <font color=\"blue\"><b>(학습률 등의) 하이퍼파라미터를 어떻게 설정하느냐에 따라서도 결과가 바뀜 </b></font>\n",
    "\n",
    "<br>\n",
    "\n",
    "* 네 기법 각자의 장단점이 있기 때문에 <u>모든 문제에서 항상 뛰어난 기법이 존재하지 않음</u>\n",
    "* 본 책에서는,\n",
    " - 지금도 많은 연구에서 SGD를 사용\n",
    " - 모멘텀과 AdaGrad도 시도해 볼만한 가치가 있는 방법\n",
    " - 요즘 많은 분들이 Adam에 만족해하며 사용\n",
    "   - <font color=\"red\"><b> => 각자의 상황을 고려해 여러 가지로 시도하는 것이 중요 </b></font>\n",
    "\n",
    "<img src=\"12.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.8 MNIST 데이터셋으로 본 갱신 방법 비교\n",
    "\n",
    "* 손글씨 숫자 인식을 대상으로 네 기법 비교 \n",
    " - 각 층이 100개의 뉴런으로 구성된 5층 신경망에서 ReLU를 활성화 함수로 사용해 측점\n",
    " \n",
    "<br>\n",
    "\n",
    "* [그림 6-9]의 결과\n",
    " - SGD의 학습 진도가 가장 느림\n",
    " - 이 실험에서 주의할 점은, 하이퍼파라미터인 학습률과 신경망의 구조 (층 깊이 등)에 따라 결과가 달라짐\n",
    " - 일반적으로 SGD보다 다른 세 기법이 빠르게 학습하고, 때로는 정확도가 높게 나타남\n",
    "\n",
    "<img src=\"13.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 가중치의 초기값 <font color=\"blue\"><font size=\"2\"><i>가중치 초깃값을 정하는 방법은 <u>올바른 학습을 하는데 매우 중요함</u></i></font></font>\n",
    "<font color=\"blue\"><font size=\"2\"><i>신경망 학습에서 특히 중요한 것이 가중치의 초깃값</i></font></font>\n",
    "<font color=\"blue\"><font size=\"2\"><i>가중치의 초깃값을 무엇으로 설정하느냐가 신경망 학습의 성패를 가름</i></font></font>\n",
    " - Xavier\n",
    " - He"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 6.2.1초깃값을 0으로 하면?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.2 은닉층의 활성화값 분포\n",
    "<img src=\"14.jpg\">\n",
    "<img src=\"15.jpg\">\n",
    "<img src=\"16.jpg\">\n",
    "<img src=\"17.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.3 ReLU를 사용할 때의 가중치 초깃값\n",
    "<img src=\"18.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.4 MNIST 데이터셋으로 본 가중치 초깃값 비교\n",
    "<img src=\"19.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 배치 정규화 <font color=\"blue\"><font size=\"2\"><i>배치 정규화를 이용하면 <u>학습을 빠르게 진행할 수 있으며, 초깃값에 영향을 덜 받게 됨</u></i></font></font>\n",
    "\n",
    "* (Review)\n",
    " - 가중치의 초깃값을 적절히 설정하면 각 층의 활성화값 분포가 적당히 퍼지면서 학습이 원활하게 수행됨\n",
    "\n",
    "<br>\n",
    "\n",
    "* <font size=\"3\"><b>배치 정규화</b><sup>Batch Normalization</font>\n",
    " - 각 층의 활성화를 적당히 퍼트리도록 '강제로' 하는 아이디어에서 출발한 방법\n",
    " - 2015년데 제안된 방법\n",
    " - 아직 세상에 나온지 얼마 안된 기법임에도 많은 연구자와 기술자들이 즐겨 사용하는 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.1 배치 정규화 \n",
    "\n",
    "* 배치 정규화가 주목받는 이유\n",
    " - <b>학습을 빨리 진행할 수 있음</b> (학습 속도 개선)\n",
    " - <b>초깃값에 크게 의존하지 않음</b> (골치 아픈 초깃값 선택 장애여 안녕!!)\n",
    " - <b>오버피팅을 억제함</b> (드롭아웃 등의 필요성 감소)\n",
    "\n",
    "<br>\n",
    "\n",
    "* <font size=\"3\"><b>배치 정규화</b></font>\n",
    " - 각 층에서의 활성화값이 적당히 분포되도록 조정하는 것\n",
    " - 배치 정규화<sup>Batch Norm</sup> 계층을 신경망에 삽입\n",
    " - 학습 시 미니배치를 단위로 정규화\n",
    " - 데이터 분포가 평균이 0, 분산이 1이 되도록 정규화\n",
    " \n",
    "<img src=\"20.jpg\">\n",
    "<img src=\"21.jpg\">\n",
    "\n",
    "* 미니배치 B = {x1, x2, .... xm}이라는 m개의 입력 데이터의 집합에 대해 평균 μ<sub>B</sub>와 분산 δ<sub>B</sub><sup>2</sup>\n",
    "* 입력 데이터를 평균이 0, 분산이 1이 되게 (적절한 분포가 되게) 정규화함\n",
    "* ε 기호<sup>epsilon, 엡실론</sup>는 작은 값(예컨데 10ㄷ-7 등)으로, <u>0으로 나누는 사태를 예방하는 역할</u>\n",
    "* [식 6.7]\n",
    " - 미니배치 입력 데이터를 평균 0, 분산 1인 데이터로 변환하는 역할\n",
    " - 이 처리를 활성화 함수의 앞 (혹은 뒤)에 삽입함으로써 <u>데이터 분포가 덜 치우치게 할 수 있음</u>\n",
    "\n",
    "<img src=\"22.jpg\">\n",
    "\n",
    "* 배치 정규화 계층마다 이 정규화된 데이터에 고유한 <b>확대<sup>scale</sup>와 이동<sup>shift</sup> 변환</b> 수행\n",
    " - γ : 확대 담당\n",
    " - β : 이동 담당\n",
    " - 두 값은 처음에는 γ = 1, β = 0부터 시작하고, 학습하면서 적합한 값으로 조정해나감\n",
    " \n",
    "<br>\n",
    "\n",
    "* 배치 정규화의 알고리즘\n",
    " - 신경망에서 순전파 때 적용\n",
    " - 계산 그래프로는 [그림 6-17] 처럼 그릴 수 있음\n",
    " <img src=\"23.jpg\">\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.2 배치 정규화 효과\n",
    "\n",
    "* MNIST 데이터셋을 사용하여 배치 정규화 계층을 사용할 때와 사용하지 않을 때의 학습 진도가 어떻게 달라지는지 확인 [그림 6-18]\n",
    " - 배치 정규화가 학습을 빨리 진전시키고 있음\n",
    "\n",
    "<img src=\"24.jpg\">\n",
    "\n",
    "* 초깃값 분포를 다양하게 줘가며 학습 진행이 어떻게 달라지는지 확인 [그림 6-19]\n",
    " - 거의 모든 경우에서 <b>배치 정규화를 사용할 때의 학습 진도가 빠른 것으로 나타남</b>\n",
    " - (실제로) 배치 정규화를 이용하지 않는 경우엔 <u>초깃값이 잘 분포되어 있지 않으면 학습이 전혀 진행되지 않는 모습 확인</u> 가능\n",
    "\n",
    "<br>\n",
    "* Consequently, \n",
    " - <font size=\"3\"><font color=\"Red\"><b> 배치 정규화를 사용하면 학습이 빨라지며, 가중치 초깃값에 크게 의존하지 않아도 됨 </b></font></font>\n",
    "\n",
    "<img src=\"25.jpg\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 바른 학습을 위해\n",
    " - 오버피팅\n",
    " - 가중치 감소\n",
    "<font color=\"blue\"><font size=\"1\"><i>오버피팅의 대응책인 정규화 방법</i></font></font>\n",
    " - 드롭아웃 \n",
    " <font color=\"blue\"><font size=\"1\"><i>오버피팅의 대응책인 정규화 방법</i></font></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4.1 오버피팅\n",
    "\n",
    "* <font size=\"3\"><b>오버피팅</b></font>\n",
    " - 신경망이 훈련 데이터에만 지나치게 적응되어 그 외의 데이터에는 제대로 대응하지 못하는 상태\n",
    " - 기계학습에서 오버피팅의 문제가 되는 일이 많음\n",
    "\n",
    "<br>\n",
    "\n",
    "* 오버피팅이 발생할 수 있는 경우\n",
    " - 매개변수가 많고 표현력이 높은 모델\n",
    " - 훈련 데이터가 적음\n",
    "\n",
    "<br> \n",
    "\n",
    "* 이 두 요건을 일부러 충족하여 오버피팅 발생 예시\n",
    " - 60,000개인 MNIST 데이터셋의 훈련 데이터 중 300개만 사용\n",
    " - 7층 네트워크를 사용하여 네트워크의 복잡성을 높임\n",
    " - 각 층의 뉴런은 100개\n",
    " - 활성화 함수는 ReLU를 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 데이터를 읽는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading train-images-idx3-ubyte.gz ... \n",
      "Done\n",
      "Downloading train-labels-idx1-ubyte.gz ... \n",
      "Done\n",
      "Downloading t10k-images-idx3-ubyte.gz ... \n",
      "Done\n",
      "Downloading t10k-labels-idx1-ubyte.gz ... \n",
      "Done\n",
      "Converting train-images-idx3-ubyte.gz to NumPy Array ...\n",
      "Done\n",
      "Converting train-labels-idx1-ubyte.gz to NumPy Array ...\n",
      "Done\n",
      "Converting t10k-images-idx3-ubyte.gz to NumPy Array ...\n",
      "Done\n",
      "Converting t10k-labels-idx1-ubyte.gz to NumPy Array ...\n",
      "Done\n",
      "Creating pickle file ...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from dataset.mnist import load_mnist\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True)\n",
    "# 오버피팅을 재현하기 위해 학습 데이터 수를 줄입\n",
    "x_train = x_train[:300]\n",
    "t_train = t_train[:300]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 훈련을 수행하는 코드\n",
    " - 에폭마다 모든 훈련 데이터와 모든 시험 데이터 각각에서 정확도 산출\n",
    " - train_acc_list와 test_acc_list에는 에폭 단위(모든 훈련 데이터를 한 번씩 본 단위)의 정확도를 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train acc:0.106666666667, test acc:0.1023\n",
      "epoch:1, train acc:0.106666666667, test acc:0.1035\n",
      "epoch:2, train acc:0.103333333333, test acc:0.1067\n",
      "epoch:3, train acc:0.126666666667, test acc:0.11\n",
      "epoch:4, train acc:0.146666666667, test acc:0.1188\n",
      "epoch:5, train acc:0.163333333333, test acc:0.1302\n",
      "epoch:6, train acc:0.173333333333, test acc:0.1443\n",
      "epoch:7, train acc:0.216666666667, test acc:0.1639\n",
      "epoch:8, train acc:0.236666666667, test acc:0.1754\n",
      "epoch:9, train acc:0.266666666667, test acc:0.1858\n",
      "epoch:10, train acc:0.283333333333, test acc:0.1981\n",
      "epoch:11, train acc:0.32, test acc:0.213\n",
      "epoch:12, train acc:0.336666666667, test acc:0.2305\n",
      "epoch:13, train acc:0.36, test acc:0.2418\n",
      "epoch:14, train acc:0.403333333333, test acc:0.2579\n",
      "epoch:15, train acc:0.413333333333, test acc:0.2675\n",
      "epoch:16, train acc:0.44, test acc:0.2816\n",
      "epoch:17, train acc:0.46, test acc:0.2915\n",
      "epoch:18, train acc:0.516666666667, test acc:0.3151\n",
      "epoch:19, train acc:0.54, test acc:0.3288\n",
      "epoch:20, train acc:0.556666666667, test acc:0.3396\n",
      "epoch:21, train acc:0.586666666667, test acc:0.3658\n",
      "epoch:22, train acc:0.606666666667, test acc:0.3874\n",
      "epoch:23, train acc:0.62, test acc:0.403\n",
      "epoch:24, train acc:0.646666666667, test acc:0.4104\n",
      "epoch:25, train acc:0.653333333333, test acc:0.4341\n",
      "epoch:26, train acc:0.636666666667, test acc:0.432\n",
      "epoch:27, train acc:0.66, test acc:0.452\n",
      "epoch:28, train acc:0.666666666667, test acc:0.4562\n",
      "epoch:29, train acc:0.666666666667, test acc:0.4634\n",
      "epoch:30, train acc:0.66, test acc:0.464\n",
      "epoch:31, train acc:0.68, test acc:0.4766\n",
      "epoch:32, train acc:0.7, test acc:0.4978\n",
      "epoch:33, train acc:0.69, test acc:0.4948\n",
      "epoch:34, train acc:0.686666666667, test acc:0.5067\n",
      "epoch:35, train acc:0.7, test acc:0.5102\n",
      "epoch:36, train acc:0.713333333333, test acc:0.5184\n",
      "epoch:37, train acc:0.72, test acc:0.5263\n",
      "epoch:38, train acc:0.723333333333, test acc:0.5325\n",
      "epoch:39, train acc:0.726666666667, test acc:0.5369\n",
      "epoch:40, train acc:0.74, test acc:0.547\n",
      "epoch:41, train acc:0.776666666667, test acc:0.5561\n",
      "epoch:42, train acc:0.773333333333, test acc:0.5582\n",
      "epoch:43, train acc:0.803333333333, test acc:0.5742\n",
      "epoch:44, train acc:0.816666666667, test acc:0.5709\n",
      "epoch:45, train acc:0.81, test acc:0.5832\n",
      "epoch:46, train acc:0.82, test acc:0.5832\n",
      "epoch:47, train acc:0.843333333333, test acc:0.5936\n",
      "epoch:48, train acc:0.836666666667, test acc:0.5984\n",
      "epoch:49, train acc:0.856666666667, test acc:0.6133\n",
      "epoch:50, train acc:0.85, test acc:0.6114\n",
      "epoch:51, train acc:0.856666666667, test acc:0.6256\n",
      "epoch:52, train acc:0.843333333333, test acc:0.6187\n",
      "epoch:53, train acc:0.87, test acc:0.6374\n",
      "epoch:54, train acc:0.88, test acc:0.6416\n",
      "epoch:55, train acc:0.88, test acc:0.6383\n",
      "epoch:56, train acc:0.896666666667, test acc:0.6573\n",
      "epoch:57, train acc:0.893333333333, test acc:0.6627\n",
      "epoch:58, train acc:0.883333333333, test acc:0.6754\n",
      "epoch:59, train acc:0.893333333333, test acc:0.6735\n",
      "epoch:60, train acc:0.89, test acc:0.6785\n",
      "epoch:61, train acc:0.906666666667, test acc:0.6789\n",
      "epoch:62, train acc:0.906666666667, test acc:0.677\n",
      "epoch:63, train acc:0.92, test acc:0.6812\n",
      "epoch:64, train acc:0.92, test acc:0.6912\n",
      "epoch:65, train acc:0.906666666667, test acc:0.6827\n",
      "epoch:66, train acc:0.933333333333, test acc:0.6893\n",
      "epoch:67, train acc:0.936666666667, test acc:0.7019\n",
      "epoch:68, train acc:0.92, test acc:0.6944\n",
      "epoch:69, train acc:0.93, test acc:0.6978\n",
      "epoch:70, train acc:0.933333333333, test acc:0.6974\n",
      "epoch:71, train acc:0.94, test acc:0.7073\n",
      "epoch:72, train acc:0.94, test acc:0.7\n",
      "epoch:73, train acc:0.946666666667, test acc:0.7034\n",
      "epoch:74, train acc:0.95, test acc:0.7067\n",
      "epoch:75, train acc:0.953333333333, test acc:0.7116\n",
      "epoch:76, train acc:0.953333333333, test acc:0.7177\n",
      "epoch:77, train acc:0.953333333333, test acc:0.7181\n",
      "epoch:78, train acc:0.96, test acc:0.7168\n",
      "epoch:79, train acc:0.953333333333, test acc:0.7138\n",
      "epoch:80, train acc:0.956666666667, test acc:0.7166\n",
      "epoch:81, train acc:0.963333333333, test acc:0.7127\n",
      "epoch:82, train acc:0.963333333333, test acc:0.713\n",
      "epoch:83, train acc:0.97, test acc:0.7205\n",
      "epoch:84, train acc:0.97, test acc:0.7187\n",
      "epoch:85, train acc:0.97, test acc:0.7212\n",
      "epoch:86, train acc:0.973333333333, test acc:0.723\n",
      "epoch:87, train acc:0.98, test acc:0.7219\n",
      "epoch:88, train acc:0.983333333333, test acc:0.726\n",
      "epoch:89, train acc:0.983333333333, test acc:0.7261\n",
      "epoch:90, train acc:0.983333333333, test acc:0.727\n",
      "epoch:91, train acc:0.98, test acc:0.7236\n",
      "epoch:92, train acc:0.983333333333, test acc:0.7285\n",
      "epoch:93, train acc:0.99, test acc:0.7314\n",
      "epoch:94, train acc:0.99, test acc:0.7274\n",
      "epoch:95, train acc:0.99, test acc:0.7307\n",
      "epoch:96, train acc:0.99, test acc:0.7298\n",
      "epoch:97, train acc:0.99, test acc:0.7338\n",
      "epoch:98, train acc:0.99, test acc:0.7298\n",
      "epoch:99, train acc:0.99, test acc:0.7354\n",
      "epoch:100, train acc:0.99, test acc:0.736\n",
      "epoch:101, train acc:0.993333333333, test acc:0.7295\n",
      "epoch:102, train acc:0.99, test acc:0.7357\n",
      "epoch:103, train acc:0.99, test acc:0.7365\n",
      "epoch:104, train acc:0.99, test acc:0.741\n",
      "epoch:105, train acc:0.99, test acc:0.7398\n",
      "epoch:106, train acc:0.99, test acc:0.7393\n",
      "epoch:107, train acc:0.99, test acc:0.7367\n",
      "epoch:108, train acc:0.99, test acc:0.7361\n",
      "epoch:109, train acc:0.993333333333, test acc:0.7304\n",
      "epoch:110, train acc:0.993333333333, test acc:0.7363\n",
      "epoch:111, train acc:0.993333333333, test acc:0.738\n",
      "epoch:112, train acc:0.993333333333, test acc:0.7417\n",
      "epoch:113, train acc:0.993333333333, test acc:0.7389\n",
      "epoch:114, train acc:0.993333333333, test acc:0.7367\n",
      "epoch:115, train acc:0.993333333333, test acc:0.7399\n",
      "epoch:116, train acc:0.993333333333, test acc:0.7433\n",
      "epoch:117, train acc:0.996666666667, test acc:0.7417\n",
      "epoch:118, train acc:0.993333333333, test acc:0.7409\n",
      "epoch:119, train acc:0.993333333333, test acc:0.74\n",
      "epoch:120, train acc:0.993333333333, test acc:0.7408\n",
      "epoch:121, train acc:0.996666666667, test acc:0.7443\n",
      "epoch:122, train acc:0.993333333333, test acc:0.7469\n",
      "epoch:123, train acc:0.996666666667, test acc:0.7439\n",
      "epoch:124, train acc:0.996666666667, test acc:0.745\n",
      "epoch:125, train acc:0.996666666667, test acc:0.7457\n",
      "epoch:126, train acc:0.996666666667, test acc:0.7423\n",
      "epoch:127, train acc:0.996666666667, test acc:0.7468\n",
      "epoch:128, train acc:0.996666666667, test acc:0.744\n",
      "epoch:129, train acc:0.996666666667, test acc:0.7462\n",
      "epoch:130, train acc:0.996666666667, test acc:0.744\n",
      "epoch:131, train acc:0.996666666667, test acc:0.7462\n",
      "epoch:132, train acc:0.996666666667, test acc:0.7416\n",
      "epoch:133, train acc:0.996666666667, test acc:0.7442\n",
      "epoch:134, train acc:0.996666666667, test acc:0.7454\n",
      "epoch:135, train acc:0.996666666667, test acc:0.7458\n",
      "epoch:136, train acc:0.996666666667, test acc:0.7456\n",
      "epoch:137, train acc:0.996666666667, test acc:0.7459\n",
      "epoch:138, train acc:0.996666666667, test acc:0.7476\n",
      "epoch:139, train acc:0.996666666667, test acc:0.748\n",
      "epoch:140, train acc:0.996666666667, test acc:0.7469\n",
      "epoch:141, train acc:0.996666666667, test acc:0.7477\n",
      "epoch:142, train acc:0.996666666667, test acc:0.7469\n",
      "epoch:143, train acc:0.996666666667, test acc:0.7475\n",
      "epoch:144, train acc:0.996666666667, test acc:0.7447\n",
      "epoch:145, train acc:0.996666666667, test acc:0.7475\n",
      "epoch:146, train acc:0.996666666667, test acc:0.746\n",
      "epoch:147, train acc:0.996666666667, test acc:0.7465\n",
      "epoch:148, train acc:0.996666666667, test acc:0.7478\n",
      "epoch:149, train acc:0.996666666667, test acc:0.7463\n",
      "epoch:150, train acc:0.996666666667, test acc:0.7453\n",
      "epoch:151, train acc:0.996666666667, test acc:0.7462\n",
      "epoch:152, train acc:0.996666666667, test acc:0.7485\n",
      "epoch:153, train acc:0.996666666667, test acc:0.7469\n",
      "epoch:154, train acc:0.996666666667, test acc:0.7474\n",
      "epoch:155, train acc:0.996666666667, test acc:0.7466\n",
      "epoch:156, train acc:0.996666666667, test acc:0.7471\n",
      "epoch:157, train acc:0.996666666667, test acc:0.7476\n",
      "epoch:158, train acc:0.996666666667, test acc:0.7501\n",
      "epoch:159, train acc:0.996666666667, test acc:0.7494\n",
      "epoch:160, train acc:0.996666666667, test acc:0.7499\n",
      "epoch:161, train acc:0.996666666667, test acc:0.7489\n",
      "epoch:162, train acc:1.0, test acc:0.748\n",
      "epoch:163, train acc:1.0, test acc:0.7513\n",
      "epoch:164, train acc:1.0, test acc:0.7509\n",
      "epoch:165, train acc:1.0, test acc:0.751\n",
      "epoch:166, train acc:1.0, test acc:0.7502\n",
      "epoch:167, train acc:1.0, test acc:0.7499\n",
      "epoch:168, train acc:1.0, test acc:0.7496\n",
      "epoch:169, train acc:1.0, test acc:0.7482\n",
      "epoch:170, train acc:1.0, test acc:0.7496\n",
      "epoch:171, train acc:1.0, test acc:0.7496\n",
      "epoch:172, train acc:1.0, test acc:0.7522\n",
      "epoch:173, train acc:1.0, test acc:0.7521\n",
      "epoch:174, train acc:1.0, test acc:0.7528\n",
      "epoch:175, train acc:1.0, test acc:0.7519\n",
      "epoch:176, train acc:1.0, test acc:0.7526\n",
      "epoch:177, train acc:1.0, test acc:0.7513\n",
      "epoch:178, train acc:1.0, test acc:0.7517\n",
      "epoch:179, train acc:1.0, test acc:0.7528\n",
      "epoch:180, train acc:1.0, test acc:0.7522\n",
      "epoch:181, train acc:1.0, test acc:0.7518\n",
      "epoch:182, train acc:1.0, test acc:0.7523\n",
      "epoch:183, train acc:1.0, test acc:0.7535\n",
      "epoch:184, train acc:1.0, test acc:0.7542\n",
      "epoch:185, train acc:1.0, test acc:0.7538\n",
      "epoch:186, train acc:1.0, test acc:0.7529\n",
      "epoch:187, train acc:1.0, test acc:0.7511\n",
      "epoch:188, train acc:1.0, test acc:0.7534\n",
      "epoch:189, train acc:1.0, test acc:0.7515\n",
      "epoch:190, train acc:1.0, test acc:0.7533\n",
      "epoch:191, train acc:1.0, test acc:0.752\n",
      "epoch:192, train acc:1.0, test acc:0.7519\n",
      "epoch:193, train acc:1.0, test acc:0.753\n",
      "epoch:194, train acc:1.0, test acc:0.7534\n",
      "epoch:195, train acc:1.0, test acc:0.7534\n",
      "epoch:196, train acc:1.0, test acc:0.7526\n",
      "epoch:197, train acc:1.0, test acc:0.7541\n",
      "epoch:198, train acc:1.0, test acc:0.7548\n",
      "epoch:199, train acc:1.0, test acc:0.7553\n",
      "epoch:200, train acc:1.0, test acc:0.7556\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from common.multi_layer_net import MultiLayerNet\n",
    "from common.optimizer import SGD\n",
    "\n",
    "network = MultiLayerNet(input_size=784, hidden_size_list=[100, 100, 100, 100, 100, 100], output_size=10)\n",
    "optimizer = SGD(lr=0.01) # 학습률이 0.01인 SGD로 매개변수 갱신\n",
    "\n",
    "max_epochs = 201\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "epoch_cnt = 0\n",
    "\n",
    "for i in range(1000000000):\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "\n",
    "    grads = network.gradient(x_batch, t_batch)\n",
    "    optimizer.update(network.params, grads)\n",
    "\n",
    "    if i % iter_per_epoch == 0:\n",
    "        train_acc = network.accuracy(x_train, t_train)\n",
    "        test_acc = network.accuracy(x_test, t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "\n",
    "        print(\"epoch:\" + str(epoch_cnt) + \", train acc:\" + str(train_acc) + \", test acc:\" + str(test_acc))\n",
    "\n",
    "        epoch_cnt += 1\n",
    "        if epoch_cnt >= max_epochs:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 훈련 데이터를 사용하여 측정한 정확도\n",
    " - 100 에폭을 지나는 무렵부터 거의 100%\n",
    " - 그러나, 시험 데이터에 대해서는 큰 차이를 보임\n",
    " - 이처럼, 정확도가 크게 벌어지는 것은 <font size=\"3\"><font color=\"red\"><b>훈련 데이터에만 적응<sup>fitting</sup>해버린 결과</b></font></font>\n",
    " - 훈련 때 사용하지 않은 범용 데이터(시험 데이터)에는 제대로 대응하지 못함\n",
    " \n",
    "<img src=\"50.JPG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4.2 가중치 감소\n",
    "\n",
    "* <b>가중치 감소</b><sup>weight decay</sup>\n",
    " - 학습 과정에서 큰 가중치에 대해서는 그에 상응하는 큰 페널티를 부과하여 오버피팅을 억제하는 방법\n",
    "   - ※ 오버피팅 : 가중치 매개변수의 값이 커서 발생하는 경우가 많음\n",
    "* 신경망 학습의 목적 -> 손실 함수의 값을 줄이는 것\n",
    "* 예시)\n",
    " - ex)가중치의 제곱 법칙(L2 법칙)을 손실 함수에 더함 -> <font color=\"red\"><b>가중치가 커지는 것을 억제</b></font>\n",
    " - 가중치를 <b>W</b>라 하면 L2 법칙에 따른 가중치 감소는 <b>1/2λW<sup>2</sup></b>이 되고, 이 <b>1/2λW<sup>2</sup></b>을 손실 함수에 더함\n",
    " - λ<sup>람다</sup> : 정규화의 세기를 조절하는 하이퍼파라미터\n",
    " - λ를 크게 설정할수록 큰 가중치에 대한 페널티가 커짐\n",
    " - 1/2λW<sup>2</sup></b> : 1/2은 1/2λW<sup>2</sup></b>의 미분 결과인 λW를 조절하는 역할의 상수\n",
    "* 가중치 감소는 모든 가중치 각각의 손실 함수에 1/2λW<sup>2</sup></b>을 더함\n",
    " - 따라서, <font color=\"red\"><b>가중치의 기울기를 구하는 계산에서는 그동안의 오차역전파법에 따른 결과에 정규화 항을 미분한 λW를 더함</b></font>\n",
    "\n",
    "<br>\n",
    "\n",
    "* λ = 0.1로 가중치 감소를 적용한 실험 정확도 추이 분석\n",
    " - 훈련 데이터에 대한 정확도와 시험 데이터에 대한 정확도에는 [그림 6-20]과 비교했을 때 여전히 차이는 존재하지만,\n",
    " - 가중치 감소를 이용하지 않은 [그림 6-20]과 비교하면 그 차이가 줄어듦을 확인\n",
    "   - <font color=\"red\"><b>오버피팅이 억제됨</b></font>\n",
    " - 더하여, (앞서와 달리) 훈련 데이터에 대한 정확도가 100%(1.0)에 도달하지 못한 점도 주목해야 함\n",
    "\n",
    "<img src=\"51.JPG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4.3 드롭아웃\n",
    "\n",
    "* (Overview) 가중치 감소\n",
    " - 오버피팅을 억제하는 방식으로 손실 함수에 가중치의 L2 법칙을 더한 방법\n",
    " - 간단하게 구현 가능\n",
    " - 어느 정도 지나친 학습을 억제할 수 있음\n",
    " - 그러나, 신경망 모델이 복잡해지면 가중치 감소만으로는 대응이 어려워짐 \n",
    "   - 이를, <font size=\"3\"><font color=\"red\"><b>드롭아웃</b></font></font><sup>Dropout</sup> 이라는 기법을 사용하여 해결 가능\n",
    "\n",
    "<br>\n",
    "\n",
    "* <font size=\"3\"><b>드롭아웃</b></font><sup>Dropout</sup>\n",
    " - 뉴런을 임의로 삭제하면서 학습하는 방법\n",
    " - 훈련 때 은닉층의 뉴런을 무작위로 골라 삭제\n",
    " - 삭제된 뉴런은 신호를 전달하지 않게됨\n",
    " - 훈련 때는 데이터를 흘릴 때마다 삭제할 뉴런을 무작위로 선택하고,\n",
    " - 시험 때는 모든 뉴런에 신호를 전달함\n",
    " - 단, 시험 때는 각 뉴런의 출력에 훈련 때 삭제한 비율을 곱하여 출력함\n",
    "\n",
    "<img src=\"52.JPG\">\n",
    "<img src=\"53.JPG\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5 적절한 하이퍼파라미터 값 찾기 <font color=\"blue\"><font size=\"2\"><i>하이퍼파라미터 값 탐색은 <u>최적 값이 존재할 법한 범위를 점차 좁히면서 하는 것이 효과적</u></i></font></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"54.JPG\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ■ Summary \n",
    "#### <u><b>신경망 학습의 핵심 개념들에 대한 분석</b><br></u>\n",
    "* <b> 6.1 매개변수 갱신 방법 </b>\n",
    "<font color=\"blue\"><font size=\"1\"><i>가중치 매개변수의 최적값을 탐색하는 최적화 방법</i></font></font>\n",
    " - 확률적 경사 하강법(SSD)\n",
    " - 모멘텀\n",
    " - AdaGrad\n",
    " - Adam\n",
    "* <b> 6.2 가중치의 초깃값 </b>\n",
    "<font color=\"blue\"><font size=\"1\"><i>가중치 초깃값을 정하는 방법은 <u>올바른 학습을 하는데 매우 중요함</u></i></font></font>\n",
    " - Xavier\n",
    " - He\n",
    "* <b> 6.3 배치 정규화 </b>\n",
    "<font color=\"blue\"><font size=\"1\"><i>배치 정규화를 이용하면 <u>학습을 빠르게 진행할 수 있으며, 초깃값에 영향을 덜 받게 됨</u></i></font></font>\n",
    "* <b> 6.4 바른 학습을 위해 </b>\n",
    " - 오버피팅\n",
    " - 가중치 감소\n",
    "  <font color=\"blue\"><font size=\"1\"><i>오버피팅의 대응책인 정규화 방법</i></font></font>\n",
    " - 드롭아웃 \n",
    " <font color=\"blue\"><font size=\"1\"><i>오버피팅의 대응책인 정규화 방법</i></font></font>\n",
    "* <b> 6.5 적절한 하이퍼파라미터 값 찾기 </b>\n",
    "<font color=\"blue\"><font size=\"1\"><i>하이퍼파라미터 값 탐색은 <u>최적 값이 존재할 법한 범위를 점차 좁히면서 하는 것이 효과적</u></i></font></font>\n",
    "#### <font color=\"red\"><b> => 신경망 (딥러닝) 학습의 효율과 정확도를 높일 수 있음</b></font><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
